{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ed68d5",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Cleaning, Revisualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2712f",
   "metadata": {},
   "source": [
    "##### Loading the Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3cf43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Load dataset\n",
    "df_clean = pd.read_csv(\"data/tech_salary_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ca777",
   "metadata": {},
   "source": [
    "##### Drop Irrelevant Columns and Level Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17d57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Irrelevant Columns\n",
    "cols_to_drop = [\"timestamp\", \"company\", \"tag\", \"otherdetails\", \"cityid\", \"dmaid\", \"rowNumber\"]\n",
    "for col in cols_to_drop:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean.drop(columns=col, inplace=True)\n",
    "\n",
    "# Drop 'level' column (too complex and not useful)\n",
    "df_clean.drop(columns=['level'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236d90f",
   "metadata": {},
   "source": [
    "##### Removing Rows where Race is Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b398f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows with known Race\n",
    "df_clean.dropna(subset=[\"Race\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db2b2a",
   "metadata": {},
   "source": [
    "##### Removing Rows where Gender is not Male/Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466f0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows with Male/Female Gender\n",
    "df_clean[\"gender\"] = df_clean[\"gender\"].str.strip().str.title()\n",
    "df_clean = df_clean[df_clean[\"gender\"].isin([\"Male\", \"Female\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c83ce2",
   "metadata": {},
   "source": [
    "##### Changing Null Values in Education to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4597875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Education with \"None\" value\n",
    "if \"Education\" in df_clean.columns:\n",
    "    df_clean[\"Education\"] = df_clean[\"Education\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479cd22",
   "metadata": {},
   "source": [
    "##### Recalculate Salary-Related Variables and Verify Mismatches\n",
    "totalyearlycompensation = basesalary + bonus + stockgrantvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a05b3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatched rows after recalculation: 0\n"
     ]
    }
   ],
   "source": [
    "# Clamp negative bonus/stockgrantvalue up to zero\n",
    "for col in [\"bonus\", \"stockgrantvalue\"]:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].clip(lower=0)\n",
    "\n",
    "# Recompute totalyearlycompensation from its components\n",
    "df_clean[\"totalyearlycompensation\"] = (\n",
    "    df_clean[\"basesalary\"].fillna(0) +\n",
    "    df_clean[\"bonus\"].fillna(0) +\n",
    "    df_clean[\"stockgrantvalue\"].fillna(0)\n",
    ")\n",
    "\n",
    "# Verify that no mismatches between totalyearlycompensation and its related variables remain\n",
    "mismatch = (\n",
    "    df_clean[\"totalyearlycompensation\"] -\n",
    "    df_clean[[\"basesalary\", \"bonus\", \"stockgrantvalue\"]].sum(axis=1)\n",
    ").abs().gt(1e-6)\n",
    "print(f\"Mismatched rows after recalculation: {mismatch.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f5bfe",
   "metadata": {},
   "source": [
    "##### Synchronizing Education Binary Variables\n",
    "Masters_Degree, Bachelors_Degree, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed36bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronize education binary variables\n",
    "edu_bins = [\n",
    "    (\"Doctorate\",       \"Doctorate_Degree\"),\n",
    "    (\"Masters\",         \"Masters_Degree\"),\n",
    "    (\"Bachelors\",       \"Bachelors_Degree\"),\n",
    "    (\"Some_College\",    \"Some_College\"),\n",
    "    (\"Highschool\",      \"Highschool\")\n",
    "]\n",
    "\n",
    "def fix_education(row):\n",
    "    flags = row[[col for _, col in edu_bins]]\n",
    "    if flags.sum() == 1:\n",
    "        return row\n",
    "    row[[col for _, col in edu_bins]] = 0\n",
    "    level = str(row.get(\"Education\", \"\")).strip().title()\n",
    "    for label, col in edu_bins:\n",
    "        if level.startswith(label):\n",
    "            row[col] = 1\n",
    "            break\n",
    "    return row\n",
    "\n",
    "df_clean = df_clean.apply(fix_education, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1feb19",
   "metadata": {},
   "source": [
    "##### Duplication of Dataframe for Outlier Elimination (Tukey's Fence Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fab4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_v2 = df_clean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31fcba4",
   "metadata": {},
   "source": [
    "##### Identifying Numeric Columns and Computing Q1, Q3 and IQR for each Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee1822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'totalyearlycompensation',\n",
    "    'basesalary',\n",
    "    'bonus',\n",
    "    'stockgrantvalue',\n",
    "    'yearsofexperience',\n",
    "    'yearsatcompany'\n",
    "]\n",
    "\n",
    "Q1 = df_cleaned_v2[numeric_cols].quantile(0.25)\n",
    "Q3 = df_cleaned_v2[numeric_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be68df2",
   "metadata": {},
   "source": [
    "##### Creating Mask for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb79edab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 3446 / 22200 rows as outliers (15.5%)\n"
     ]
    }
   ],
   "source": [
    "# Build Mask - True if row is within [Q1 - 1.5*IQR, Q3 + 1.5IQR] for EVERY numeric column\n",
    "fence_low  = Q1 - 1.5 * IQR\n",
    "fence_high = Q3 + 1.5 * IQR\n",
    "\n",
    "outlier_mask = pd.concat([\n",
    "    (df_cleaned_v2[col] < fence_low[col]) |\n",
    "    (df_cleaned_v2[col] > fence_high[col])\n",
    "    for col in numeric_cols\n",
    "], axis=1).any(axis=1)\n",
    "\n",
    "# Negating it to get non-outliers (using logical not)\n",
    "mask = ~outlier_mask\n",
    "\n",
    "n_before = len(df_cleaned_v2)\n",
    "n_after = mask.sum()\n",
    "print(f\"Dropping {n_before-n_after} / {n_before} rows as outliers ({(n_before-n_after)/n_before:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a6a23f",
   "metadata": {},
   "source": [
    "##### Copying Outlier-free Data to new Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd9988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df_cleaned_v2.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62aeb0c",
   "metadata": {},
   "source": [
    "##### Removing Duplicate Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307d4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df_no_outliers.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad1533",
   "metadata": {},
   "source": [
    "##### Removing Derivative Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c025384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df_no_outliers.drop(columns=[\"basesalary\", \"stockgrantvalue\", \"bonus\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f73230",
   "metadata": {},
   "source": [
    "##### Comparison of Original and Preprocessed Data and Exporting the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a5900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: 62,642 rows × 24 columns.\n",
      "After cleaning: 18,570 rows × 13 columns.\n",
      "Dataset saved to tech_salary_data_CLEANED.csv.\n"
     ]
    }
   ],
   "source": [
    "# Show the final shape of clean dataset and export to csv\n",
    "print(\"Before cleaning: 62,642 rows × 24 columns.\")\n",
    "print(f\"After cleaning: {df_no_outliers.shape[0]:,} rows × {df_no_outliers.shape[1]} columns.\")\n",
    "\n",
    "# Export data to new csv file\n",
    "df_no_outliers.to_csv(\"tech_salary_data_CLEANED.csv\", index=False)\n",
    "print(\"Dataset saved to tech_salary_data_CLEANED.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca793f",
   "metadata": {},
   "source": [
    "##### Column Types and Missing Values of Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8751823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Columns and Data Types ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18570 entries, 0 to 18569\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   title                    18570 non-null  object \n",
      " 1   totalyearlycompensation  18570 non-null  float64\n",
      " 2   location                 18570 non-null  object \n",
      " 3   yearsofexperience        18570 non-null  float64\n",
      " 4   yearsatcompany           18570 non-null  float64\n",
      " 5   gender                   18570 non-null  object \n",
      " 6   Masters_Degree           18570 non-null  int64  \n",
      " 7   Bachelors_Degree         18570 non-null  int64  \n",
      " 8   Doctorate_Degree         18570 non-null  int64  \n",
      " 9   Highschool               18570 non-null  int64  \n",
      " 10  Some_College             18570 non-null  int64  \n",
      " 11  Race                     18570 non-null  object \n",
      " 12  Education                18570 non-null  object \n",
      "dtypes: float64(3), int64(5), object(5)\n",
      "memory usage: 1.8+ MB\n",
      "None \n",
      "\n",
      "=== Missing Value Counts ===\n",
      "title                      0\n",
      "totalyearlycompensation    0\n",
      "location                   0\n",
      "yearsofexperience          0\n",
      "yearsatcompany             0\n",
      "gender                     0\n",
      "Masters_Degree             0\n",
      "Bachelors_Degree           0\n",
      "Doctorate_Degree           0\n",
      "Highschool                 0\n",
      "Some_College               0\n",
      "Race                       0\n",
      "Education                  0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing cleaned data\n",
    "df = pd.read_csv(\"tech_salary_data_CLEANED.csv\")\n",
    "\n",
    "# Make \"None\" value in Education into string (so it doesn't count as null)\n",
    "df['Education'] = df['Education'].replace({None: \"None\"})\n",
    "\n",
    "# Show the column types and non-null counts\n",
    "print(\"=== Columns and Data Types ===\")\n",
    "print(df.info(), \"\\n\")\n",
    "\n",
    "# Show the missing value counts\n",
    "print(\"=== Missing Value Counts ===\")\n",
    "print(df.isnull().sum(), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
