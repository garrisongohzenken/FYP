{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ed68d5",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Cleaning, Revisualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2712f",
   "metadata": {},
   "source": [
    "##### Loading the Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ef3cf43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Load dataset\n",
    "df_clean = pd.read_csv(\"../../data/tech_salary_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ca777",
   "metadata": {},
   "source": [
    "##### Drop Irrelevant Columns and Level Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Irrelevant Columns\n",
    "cols_to_drop = [\"basesalary\", \"stockgrantvalue\", \"bonus\", \"timestamp\", \"tag\", \"otherdetails\",\n",
    "                 \"cityid\", \"dmaid\", \"rowNumber\"]\n",
    "for col in cols_to_drop:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean.drop(columns=col, inplace=True)\n",
    "\n",
    "# Drop 'level' column (too complex and not useful)\n",
    "df_clean.drop(columns=['level'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236d90f",
   "metadata": {},
   "source": [
    "##### Removing Rows where Race is NaN/Null/Empty/Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5b398f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows with known Race\n",
    "df_clean.dropna(subset=[\"Race\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db2b2a",
   "metadata": {},
   "source": [
    "##### Removing Rows where Gender is not Male/Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "466f0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows with Male/Female Gender\n",
    "df_clean[\"gender\"] = df_clean[\"gender\"].str.strip().str.title()\n",
    "df_clean = df_clean[df_clean[\"gender\"].isin([\"Male\", \"Female\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a022ad2",
   "metadata": {},
   "source": [
    "##### Removing Rows where Company is Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2851ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean[\"company\"].notna()]\n",
    "\n",
    "# Also fixing multiple levels of Google in company column\n",
    "import numpy as np\n",
    "\n",
    "df_clean[\"company\"] = np.where(\n",
    "df_clean[\"company\"].astype(\"string\").str.contains(\"google\", case=False, na=False),\n",
    "\"Google\",\n",
    "df_clean[\"company\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c83ce2",
   "metadata": {},
   "source": [
    "##### Changing Null Values in Education to Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e4597875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Education with \"Other\" value\n",
    "if \"Education\" in df_clean.columns:\n",
    "    df_clean[\"Education\"] = df_clean[\"Education\"].fillna(\"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02610802",
   "metadata": {},
   "source": [
    "##### Changing Specific Location to Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['country'] = df_clean['location'].apply(lambda x: str(x).split(',')[-1].strip())\n",
    "\n",
    "# List of US state abbreviations\n",
    "us_states = ['AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL','IN','IA','KS','KY',\n",
    "             'LA','ME','MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND',\n",
    "             'OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY','DC']\n",
    "\n",
    "# Replace state codes with \"United States\"\n",
    "df_clean['country'] = df_clean['country'].apply(lambda x: 'United States' if x in us_states else x)\n",
    "\n",
    "country_map = {\n",
    "    \"UK\": \"United Kingdom\",\n",
    "    \"U.K.\": \"United Kingdom\",\n",
    "    \"England\": \"United Kingdom\",\n",
    "    \"Scotland\": \"United Kingdom\",\n",
    "    \"CA\": \"United States\",  # handled above but just in case\n",
    "    \"Hong Kong\": \"China\",\n",
    "    \"Russia\": \"Russian Federation\"\n",
    "    # add more as you see in your dataset\n",
    "}\n",
    "\n",
    "df_clean['country'] = df_clean['country'].replace(country_map)\n",
    "\n",
    "# Dropping the original 'location' column as we have extracted 'country'\n",
    "df_clean.drop(columns=['location'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f5bfe",
   "metadata": {},
   "source": [
    "##### Synchronizing Education Binary Variables\n",
    "Masters_Degree, Bachelors_Degree, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ed36bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronize education binary variables\n",
    "edu_bins = [\n",
    "    (\"Doctorate\",       \"Doctorate_Degree\"),\n",
    "    (\"Masters\",         \"Masters_Degree\"),\n",
    "    (\"Bachelors\",       \"Bachelors_Degree\"),\n",
    "    (\"Some_College\",    \"Some_College\"),\n",
    "    (\"Highschool\",      \"Highschool\")\n",
    "]\n",
    "\n",
    "def fix_education(row):\n",
    "    flags = row[[col for _, col in edu_bins]]\n",
    "    if flags.sum() == 1:\n",
    "        return row\n",
    "    row[[col for _, col in edu_bins]] = 0\n",
    "    level = str(row.get(\"Education\", \"\")).strip().title()\n",
    "    for label, col in edu_bins:\n",
    "        if level.startswith(label):\n",
    "            row[col] = 1\n",
    "            break\n",
    "    return row\n",
    "\n",
    "df_clean = df_clean.apply(fix_education, axis=1)\n",
    "\n",
    "# Dropping individual binary education columns\n",
    "df_clean.drop(columns=[\"Masters_Degree\", \n",
    "                       \"Bachelors_Degree\", \n",
    "                       \"Doctorate_Degree\",\n",
    "                       \"Highschool\",\n",
    "                       \"Some_College\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1feb19",
   "metadata": {},
   "source": [
    "##### Duplication of Dataframe for Outlier Elimination (Tukey's Fence Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6fab4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_v2 = df_clean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31fcba4",
   "metadata": {},
   "source": [
    "##### Identifying Numeric Columns and Computing Q1, Q3 and IQR for each Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dee1822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    'totalyearlycompensation',\n",
    "    'yearsofexperience',\n",
    "    'yearsatcompany'\n",
    "]\n",
    "\n",
    "Q1 = df_cleaned_v2[numeric_cols].quantile(0.25)\n",
    "Q3 = df_cleaned_v2[numeric_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be68df2",
   "metadata": {},
   "source": [
    "##### Creating Mask for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cb79edab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 1957 / 22198 rows as outliers (8.8%)\n"
     ]
    }
   ],
   "source": [
    "# Build Mask - True if row is within [Q1 - 1.5*IQR, Q3 + 1.5IQR] for EVERY numeric column\n",
    "fence_low  = Q1 - 1.5 * IQR\n",
    "fence_high = Q3 + 1.5 * IQR\n",
    "\n",
    "outlier_mask = pd.concat([\n",
    "    (df_cleaned_v2[col] < fence_low[col]) |\n",
    "    (df_cleaned_v2[col] > fence_high[col])\n",
    "    for col in numeric_cols\n",
    "], axis=1).any(axis=1)\n",
    "\n",
    "# Negating it to get non-outliers (using logical not)\n",
    "mask = ~outlier_mask\n",
    "\n",
    "n_before = len(df_cleaned_v2)\n",
    "n_after = mask.sum()\n",
    "print(f\"Dropping {n_before-n_after} / {n_before} rows as outliers ({(n_before-n_after)/n_before:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a6a23f",
   "metadata": {},
   "source": [
    "##### Copying Outlier-free Data to new Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4bd9988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df_cleaned_v2.loc[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62aeb0c",
   "metadata": {},
   "source": [
    "##### Removing Duplicate Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "307d4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df_no_outliers.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f73230",
   "metadata": {},
   "source": [
    "##### Comparison of Original and Preprocessed Data and Exporting the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "38a5900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: 62,642 rows × 24 columns.\n",
      "After cleaning: 19,878 rows × 9 columns.\n",
      "Dataset saved to tech_salary_data_CLEANED.csv.\n"
     ]
    }
   ],
   "source": [
    "# Show the final shape of clean dataset and export to csv\n",
    "print(\"Before cleaning: 62,642 rows × 24 columns.\")\n",
    "print(f\"After cleaning: {df_no_outliers.shape[0]:,} rows × {df_no_outliers.shape[1]} columns.\")\n",
    "\n",
    "# Export data to new csv file\n",
    "df_no_outliers.to_csv(\"../../data/tech_salary_data_CLEANED.csv\", index=False)\n",
    "print(\"Dataset saved to tech_salary_data_CLEANED.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca793f",
   "metadata": {},
   "source": [
    "##### Column Types and Missing Values of Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8751823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Columns and Data Types ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19878 entries, 0 to 19877\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   company                  19878 non-null  object \n",
      " 1   title                    19878 non-null  object \n",
      " 2   totalyearlycompensation  19878 non-null  int64  \n",
      " 3   yearsofexperience        19878 non-null  float64\n",
      " 4   yearsatcompany           19878 non-null  float64\n",
      " 5   gender                   19878 non-null  object \n",
      " 6   Race                     19878 non-null  object \n",
      " 7   Education                19878 non-null  object \n",
      " 8   country                  19878 non-null  object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 1.4+ MB\n",
      "None \n",
      "\n",
      "=== Missing Value Counts ===\n",
      "company                    0\n",
      "title                      0\n",
      "totalyearlycompensation    0\n",
      "yearsofexperience          0\n",
      "yearsatcompany             0\n",
      "gender                     0\n",
      "Race                       0\n",
      "Education                  0\n",
      "country                    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing cleaned data\n",
    "df = pd.read_csv(\"../../data/tech_salary_data_CLEANED.csv\")\n",
    "\n",
    "# Show the column types and non-null counts\n",
    "print(\"=== Columns and Data Types ===\")\n",
    "print(df.info(), \"\\n\")\n",
    "\n",
    "# Show the missing value counts\n",
    "print(\"=== Missing Value Counts ===\")\n",
    "print(df.isnull().sum(), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
